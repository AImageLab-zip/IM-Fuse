# Name of the paper

[[Paper]](PAPER_LINK) [[Code]](REPO_LINK) CONFERENCE_NAME YYYY
![LCKD overview](/templates/TEMPLATE_IMAGE.png)

âœ… Tested at commit: 
??????? 

## Requirements
This code was tested using:
```
python==PYTHON_VERSION
torch==TORCH_VERSION+CUDA_VERSION
```
Detailed versioning of every package can be found in the requirements.txt file

This code currently runs only on machines with CUDA support. GPU access is required for all processing steps.
## How to run
Before running any code, ensure you have correctly downloaded the BraTS 2023 Challenge dataset, specifically the subset for [Glioma Segmentation](https://www.synapse.org/Synapse:syn51156910/wiki/622351)\
\
Clone this repository, create a python env for the project and activate it. Then install all the dependencies with pip.
```
cd FOLDER_NAME
python -m venv FOLDER_NAME_venv
source FOLDER_NAME_venv/bin/activate
pip install -r requirements.txt
```
If you want to track the training using wandb, setup the wandb library following [this guide](https://docs.wandb.ai/models/quickstart).

## Training
To train the model run:
```
python train.py\
  --datapath <INPUT_PATH> \                    # Directory with the preprocessed dataset
  --num-epochs <NUM_EPOCHS> \                  # Number of epochS
  --checkpoint-path <CHECKPOINT_PATH> \        # Directory for saving the checkpoints
  --wandb-project-name PROJECT NAME \          # Optional, allows for wandb tracking
  --num-workers <NUM_WORKERS> \                # Number of workers of the dataloaders
  --batch-size <BATCH SIZE> \                  # Batch size. Start with 4
```
## Testing
After training, to test the model run:
```
python test.py \
  --datapath <INPUT_PATH> \                    # Directory with the preprocessed dataset
  --savepath <OUTPUT_PATH> \                   # Directory for saving results
  --resume <RESUME_PATH> \                     # Path to the checkpoints 
```